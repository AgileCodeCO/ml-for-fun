{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import credentials\n",
    "from resource_credentials import (subscription_key, \n",
    "    resource_group_name, \n",
    "    workspace_name,\n",
    "    datastore_name,\n",
    "    storage_account_name,\n",
    "    blob_container_name,\n",
    "    storage_account_key,\n",
    "    data_asset_name)\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Workspace\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ml client\n",
    "ml_client = MLClient(credential=DefaultAzureCredential(), \n",
    "                     subscription_id=subscription_key, \n",
    "                     resource_group_name=resource_group_name)\n",
    "\n",
    "# Define the workspace\n",
    "ws = Workspace(name=workspace_name, location=\"eastus\") \n",
    "\n",
    "ws = ml_client.workspaces.begin_create(ws).result()\n",
    "print(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_workspaces = ml_client.workspaces.list()\n",
    "for workspace in current_workspaces:\n",
    "    print(workspace.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and register a Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AzureBlobDatastore, AccountKeyConfiguration\n",
    "\n",
    "ml_client = MLClient(credential=DefaultAzureCredential(), \n",
    "                     subscription_id=subscription_key, \n",
    "                     resource_group_name=resource_group_name,\n",
    "                     workspace_name=workspace_name)\n",
    "# Define the datastore\n",
    "datastore = AzureBlobDatastore(name=datastore_name, \n",
    "                                account_name=storage_account_name, \n",
    "                                container_name=blob_container_name, \n",
    "                                credentials=AccountKeyConfiguration(account_key = storage_account_key ))\n",
    "\n",
    "datastore = ml_client.create_or_update(datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a dataset to a datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Get the datastore\n",
    "datastore = ml_client.datastores.get(datastore_name)\n",
    "\n",
    "# Define path with the datastore name\n",
    "path = \"azureml://datastores/\" + datastore_name + \"/paths/loan-data/Loan+Approval+Prediction.csv\"\n",
    "data_asset = Data(name=data_asset_name, \n",
    "                  type=AssetTypes.URI_FILE, \n",
    "                  path=path)\n",
    "\n",
    "ml_client.data.create_or_update(data_asset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model using jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ml client\n",
    "ml_client = MLClient(credential=DefaultAzureCredential(), \n",
    "                     subscription_id=subscription_key, \n",
    "                     resource_group_name=resource_group_name,\n",
    "                     workspace_name=workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/diabetes-training.py\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python diabetes-training.py\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"compute-instance-sdk\",\n",
    "    display_name=\"diabetes-pythonv2-train\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data asset from local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import command\n",
    "\n",
    "\n",
    "data_asset_path = \"./src/diabetes.csv\"\n",
    "\n",
    "data = Data(path=data_asset_path, \n",
    "            type=AssetTypes.URI_FILE,\n",
    "            name=\"diabetes-local\")\n",
    "\n",
    "ml_client.data.create_or_update(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating ML Table data asset from local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "data_asset_path = \"./src/ml-table\"\n",
    "\n",
    "data = Data(path=data_asset_path, \n",
    "            type=AssetTypes.MLTABLE,\n",
    "            name=\"diabetes-table\")\n",
    "\n",
    "ml_client.data.create_or_update(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data in job command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# create a folder for the script files\n",
    "script_folder = 'src'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/move-data.py\n",
    "# import libraries\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def main(args):\n",
    "    # read data\n",
    "    df = get_data(args.input_data)\n",
    "\n",
    "    output_df = df.to_csv((Path(args.output_datastore) / \"diabetes.csv\"), index = False)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Count the rows and print the result\n",
    "    row_count = (len(df))\n",
    "    print('Analyzing {} rows of data'.format(row_count))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--input_data\", dest='input_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
    "                        type=str)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import command\n",
    "\n",
    "# configure input and output\n",
    "my_job_inputs = {\n",
    "    \"local_data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-local:1\")\n",
    "}\n",
    "\n",
    "my_job_outputs = {\n",
    "    \"datastore_data\": Output(type=AssetTypes.URI_FOLDER, path=f\"azureml://datastores/{datastore_name}/paths/diabetes-data\")\n",
    "}\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python move-data.py --input_data ${{inputs.local_data}} --output_datastore ${{outputs.datastore_data}}\",\n",
    "    inputs=my_job_inputs,\n",
    "    outputs=my_job_outputs,\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"compute-instance-sdk\",\n",
    "    display_name=\"move-diabetes-data\",\n",
    "    experiment_name=\"move-diabetes-data\"\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Azure ML environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = ml_client.environments.list()\n",
    "for env in envs:\n",
    "    print(f\"{env.name} - Version: {env.latest_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment details\n",
    "env = ml_client.environments.get(name=\"AzureML-pytorch-1.10-ubuntu18.04-py38-cuda11-gpu\", version=\"38\")\n",
    "print(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom environment with conda dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/conda-env.yml\n",
    "name: basic-env-cpu\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.11\n",
    "  - scikit-learn\n",
    "  - pandas\n",
    "  - numpy\n",
    "  - matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env = Environment(name=\"diabetes-training-env\",\n",
    "                  image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "                  conda_file=\"./src/conda-env.yml\")\n",
    "\n",
    "ml_client.environments.create_or_update(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a script with the new environment\n",
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python diabetes-training.py\",\n",
    "    environment=\"diabetes-training-env@latest\",\n",
    "    compute=\"compute-instance-sdk\",\n",
    "    display_name=\"diabetes-pythonv2-train\",\n",
    "    experiment_name=\"diabetes-training-with-custom-env\"\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "# creates a dataset based on the files in the local data folder\n",
    "training_data = Input(type=AssetTypes.MLTABLE, path=\"azureml:diabetes-table:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run AutoML experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/loving_fig_3y7d50k8b4?wsid=/subscriptions/1eba97e5-2de8-4817-b3d4-dc76880fb329/resourcegroups/DP-100-Certification/workspaces/dp100-certification-sdk&tid=60dd1145-8a3f-4e60-86a0-3db7d9a8b09b\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import automl\n",
    "\n",
    "classification_job = automl.classification(\n",
    "    training_data=training_data,\n",
    "    target_column_name=\"Diabetic\",\n",
    "    compute=\"compute-instance-sdk\",\n",
    "    primary_metric=\"accuracy\",\n",
    "    experiment_name=\"diabetes-auto-ml\",\n",
    "    display_name=\"diabetes-auto-ml\"\n",
    "    n_cross_validations=5,\n",
    "    enable_model_explainability=True\n",
    ")\n",
    "\n",
    "# set the limits (optional)\n",
    "classification_job.set_limits(\n",
    "    timeout_minutes=60, \n",
    "    trial_timeout_minutes=20, \n",
    "    max_trials=5,\n",
    "    enable_early_termination=True,\n",
    ")\n",
    "\n",
    "# set the training properties (optional)\n",
    "classification_job.set_training(\n",
    "    blocked_training_algorithms=[\"LogisticRegression\"], \n",
    "    enable_onnx_compatible_models=True\n",
    ")\n",
    "\n",
    "#classification_job.set_featurization()\n",
    "\n",
    "# Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(\n",
    "    classification_job\n",
    ")  \n",
    "\n",
    "# submit the job to the backend\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
